{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LML3JI2IU5EA"
   },
   "source": [
    "**Josh Hellings** - Practical Data Science for Economists 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTbWOxNMWjaw"
   },
   "source": [
    "First, let's import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "F64d-V_kWjJK"
   },
   "outputs": [],
   "source": [
    "import requests                     # for making HTTP requests\n",
    "from bs4 import BeautifulSoup       # for parsing HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xxHqnF4Wthg"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/drive/1X-L1pjABev2rh32KNTJWBJ2HN-4v2U28?usp=sharing\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# Web Scraping\n",
    "\n",
    "This notebook introduces web scraping with the `requests` and `BeautifulSoup` modules using some sample HTML, then we will move on a real website.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Part 1. A Basic Example\n",
    "## Searching HTML with `BeautifulSoup`\n",
    "\n",
    "BeautifulSoup is a Python library for parsing HTML documents. We can use it to extract data from HTML fetched from the web but first we'll try it out with a simple HTML example.\n",
    "- **Tip**: After working through this notebook, carry on learning about BeautifulSoup in this [tutorial](https://www.tutorialspoint.com/beautiful_soup/beautiful_soup_overview.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "iTMQA6s2WwE5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_html\n"
     ]
    }
   ],
   "source": [
    "sample_html = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "    <h1> BeautifulSoup </h1>\n",
    "    <p> BeautifulSoup is a Python library for parsing HTML documents. We can use it to extract data from HTML we fetch\n",
    "        from the web.\n",
    "        Here, we're just using it to parse some simple sample HTML.\n",
    "    </p>\n",
    "    <h2 class=\"important\"> Searching the tree </h2>\n",
    "    <p id=\"searching_description\" style=\"color: red\"> BeautifulSoup allows us to search the HTML tree in lots of different ways: by tag, by\n",
    "        id, by CSS class, and so on. </p>\n",
    "    <ol>\n",
    "        <li role=\"example_1\"> By tag: we could search for every li </li>\n",
    "        <li role=\"example_2\"> By id: we could search for the p tag with id=\"searching_description\" </li>\n",
    "        <li role=\"example_3\" class=\"important\"> By class: we could search for every tag with a given class </li>\n",
    "        <li> and so on... </li>\n",
    "    </ol>\n",
    "    <div>\n",
    "        <p>Div tags are used to group block-elements and structure the web page.</p>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "print(\"sample_html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIz6ORu7Wx8G"
   },
   "source": [
    "---\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<h4>HTML cheatsheet: Tags & Attributes</h4>\n",
    "\n",
    "An HTML element is a part of an HTML document that is made up of a start tag, some content, and then a closing tag: `<div>Some text about anything</div>`. These elements can also include attributes, which go in the start tag: `<div id=\"unique_abc\">Some text</div>`.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Tags** are the building blocks of HTML. They are used to define the structure and content of a web page. In the **`sample_html`**, **html**, **body**, **h1**, **p**, **h2**, **ol**, **li**, and **div** are examples of tags.\n",
    "- `<html>`: The root element that defines the whole HTML document.\n",
    "- `<body>`: Contains the content of an HTML document.\n",
    "- `<h1>`, `<h2>`: Heading tags used to define headings. `<h1>` represents the main heading, while `<h2>` represents a subheading (heading tags go all the way down to <b>h6</b>, which is the smallest heading).\n",
    "- `<p>`: Defines a paragraph.\n",
    "- `<ol>`: Defines an ordered list.\n",
    "- `<li>`: Defines a list item within a list.\n",
    "- `<div>`: A block-level element used as a container to group and style sections of HTML documents with CSS or manipulate them with JavaScript.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Attributes** provide additional information about an element's properties. They are always specified in the start tag of an element and usually come in name/value pairs like name=\"value\". Common tags include:\n",
    "- `class`: An attribute used to specify a class name for an element. It is used by CSS and JavaScript to perform certain tasks for elements with the specified class name.\n",
    "- `id`: An attribute used to specify a unique id for an element. It is used to identify a single element in the document. In the sample, `id=\"searching_description\"` is used to uniquely identify a paragraph.\n",
    "- `style`: Defines the inline CSS style for an element. For example, `style=\"color: red\"` changes the text colour of the element to red.\n",
    "\n",
    "<br>\n",
    "\n",
    "**IDs vs. Classes**\n",
    "- IDs are unique identifiers for elements. An ID can only be associated with a single element in an HTML document.\n",
    "- Classes are not unique. Multiple elements can share the same class. This makes classes useful for applying the same styling or behaviour to multiple elements.\n",
    "\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgRHLB_9XGNx"
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "### 1.1 **Parsing HTML with BeautifulSoup**\n",
    "\n",
    "At present, the `sample_html` variable is just a string. In order to search through it, we'll create a **Soup** object with BeautifulSoup - a searchable object representation. Using BeautifulSoup, we can search and navigate this structure in various ways:\n",
    "\n",
    "- By tag name: Finds all instances of a specified tag.\n",
    "- By ID: Finds the element with the specified ID.\n",
    "- By class name: Finds all elements that match the specified class.\n",
    "\n",
    "The BeautifulSoup object, soup, represents the parsed HTML document as a whole. With soup, you can use its methods to search for and manipulate elements based on their tags, IDs, classes, and other attributes. This flexibility makes BeautifulSoup a powerful tool for web scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OG_zX3MVXJL1",
    "outputId": "85c6367e-1616-4d7c-94ad-ddb9ac827325"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <h1>\n",
      "   BeautifulSoup\n",
      "  </h1>\n",
      "  <p>\n",
      "   BeautifulSoup is a Python library for parsing HTML documents. We can use it to extract data from HTML we fetch\n",
      "        from the web.\n",
      "        Here, we're just using it to parse some simple sample HTML.\n",
      "  </p>\n",
      "  <h2 class=\"important\">\n",
      "   Searching the tree\n",
      "  </h2>\n",
      "  <p id=\"searching_description\" style=\"color: red\">\n",
      "   BeautifulSoup allows us to search the HTML tree in lots of different ways: by tag, by\n",
      "        id, by CSS class, and so on.\n",
      "  </p>\n",
      "  <ol>\n",
      "   <li role=\"example_1\">\n",
      "    By tag: we could search for every li\n",
      "   </li>\n",
      "   <li role=\"example_2\">\n",
      "    By id: we could search for the p tag with id=\"searching_description\"\n",
      "   </li>\n",
      "   <li class=\"important\" role=\"example_3\">\n",
      "    By class: we could search for every tag with a given class\n",
      "   </li>\n",
      "   <li>\n",
      "    and so on...\n",
      "   </li>\n",
      "  </ol>\n",
      "  <div>\n",
      "   <p>\n",
      "    Div tags are used to group block-elements and structure the web page.\n",
      "   </p>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(sample_html, 'html.parser')    # Parsing the HTML using BeautifulSoup and the built-in HTML parser\n",
    "print(soup.prettify())      # Print the HTML in a nicely formatted way (with indentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EFYfuPOXTg-"
   },
   "source": [
    "Printing this `soup` object shows the same HTML, but its now stored in a way that allows us to search through it by specifying certain characteristics we want to find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsEnI7lhXVCZ"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.2 **Searching the HTML**\n",
    "\n",
    "We can now search the `soup` object to extract useful information. Let's try searching by tag, attribute, and by both.\n",
    "\n",
    "Useful BeautifulSoup methods include:\n",
    "- `.find()`: Searches for the **first** tag that matches a given name or filter, returning a single result.\n",
    "- `.find_all()`: Searches for all tags that match a given name or filter, returning a list of results.\n",
    "- `.select()`: Uses a CSS selector to search for matching tags, returning a list of results.\n",
    "- `.get_text()`: Extracts all text from a tag and its children, returning a single string (`.text` also achieves this).\n",
    "- `.get()`: Retrieves the value of a tag attribute, such as \"href\" in an `<a>` tag or \"src\" in an `<img>` tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZK_7Nz1KXbyG"
   },
   "source": [
    "<br>\n",
    "\n",
    "##### 1.2.1 **by tag**\n",
    "\n",
    "Here's an example of using .find() to find the first `<p>` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KzU8QbCNU0SX",
    "outputId": "46626ac4-b7d6-433b-e344-a5fd9f7ee92e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p> BeautifulSoup is a Python library for parsing HTML documents. We can use it to extract data from HTML we fetch\n",
      "        from the web.\n",
      "        Here, we're just using it to parse some simple sample HTML.\n",
      "    </p>\n"
     ]
    }
   ],
   "source": [
    "# Finding the first occurrence of the <p> tag\n",
    "first_p_tag = soup.find('p')    ### NOTE: find() returns the first occurrence of the tag. If you want all occurrences, use find_all()\n",
    "print(first_p_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZqtT-13XgXW"
   },
   "source": [
    "So we've extracted the first paragraph (`<p>`) element, but it includes the opening and closing tags. To get just the text, we'll use the `.get_text()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QdO2O5CRXepC",
    "outputId": "46791b38-6a8b-4694-fd25-22eef4482b0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BeautifulSoup is a Python library for parsing HTML documents. We can use it to extract data from HTML we fetch\n",
      "        from the web.\n",
      "        Here, we're just using it to parse some simple sample HTML.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(first_p_tag.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlS_JoFkXkB7"
   },
   "source": [
    "What if we want to find the text of every list (`<li>`) element on the page? We can use `find_all()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3z4uYvbOXiKJ",
    "outputId": "8f4e1157-c197-40bb-fdb8-2ce0d565401f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " By tag: we could search for every li \n",
      " By id: we could search for the p tag with id=\"searching_description\" \n",
      " By class: we could search for every tag with a given class \n",
      " and so on... \n"
     ]
    }
   ],
   "source": [
    "list_elements = soup.find_all('li') # Finding all the list elements in the HTML\n",
    "for element in list_elements:\n",
    "    print(element.text) # Printing the text of each list element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J72ON1GGXoBv"
   },
   "source": [
    "**Note:** when using `.find_all()`, any matching elements are returned as a list - even if only 1 element is returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVw7SAGJXuyI"
   },
   "source": [
    "<br>\n",
    "\n",
    "##### 1.2.2 **by id**\n",
    "\n",
    "Let's find the paragraph (`<p>`) with `id`=\"searching_description\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fH4WRmx6Xlv9",
    "outputId": "95c94bfd-3e26-4c35-9e15-15a84303f9ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"searching_description\" style=\"color: red\"> BeautifulSoup allows us to search the HTML tree in lots of different ways: by tag, by\n",
      "        id, by CSS class, and so on. </p>\n",
      "\n",
      "Just the text:  BeautifulSoup allows us to search the HTML tree in lots of different ways: by tag, by\n",
      "        id, by CSS class, and so on. \n"
     ]
    }
   ],
   "source": [
    "# instead of using find_all, we can use `find()` to find the first element that matches the search criteria\n",
    "description_element = soup.find('p', {'id': 'searching_description'}) # Finding the paragraph with id=\"searching_description\"\n",
    "print(description_element)\n",
    "\n",
    "print('\\nJust the text:', description_element.text) # Printing the text of the paragraph with id=\"searching_description\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5RHSKf0Xy0z"
   },
   "source": [
    "As well as getting text *within* HTML elements, we can extract the attribute values of that element. Let's get the style attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ysotyqP6XyW0",
    "outputId": "1a592f68-993b-40f9-fe54-4442b85310f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph style: color: red\n"
     ]
    }
   ],
   "source": [
    "print('Paragraph style:', description_element['style']) # Printing the value of the style attribute of the paragraph with id=\"searching_description\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09zZmPLDX2rt"
   },
   "source": [
    "<br>\n",
    "\n",
    "##### 1.2.3 **by class**\n",
    "\n",
    "Let's find all elements with the `class` `important`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2VGRyavCX0w2",
    "outputId": "52c1bf58-d888-4047-c9a6-91c847a5fcaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h2 class=\"important\"> Searching the tree </h2>, <li class=\"important\" role=\"example_3\"> By class: we could search for every tag with a given class </li>]\n"
     ]
    }
   ],
   "source": [
    "important_elements = soup.find_all(class_='important') # Finding all the elements with class=\"important\"\n",
    "print(important_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wu4RCOphX5Gn"
   },
   "source": [
    "Let's view these elements individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-_7eju9uX6cr",
    "outputId": "1f656307-b4e8-4392-8374-7183e771ea1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 elements with class='important'\n",
      "<h2 class=\"important\"> Searching the tree </h2>\n",
      "<li class=\"important\" role=\"example_3\"> By class: we could search for every tag with a given class </li>\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(important_elements)} elements with class='important'\")\n",
    "for element in important_elements:\n",
    "    print(element) # Printing each element with class=\"important\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMFIVlu-X9to"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.2.4 **Bonus**: custom searching\n",
    "\n",
    "we can search in any way we want by supplying a function of our own\n",
    "\n",
    "let's write a simple function that identifies whether an element's `role` attribute that starts with `example_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ylbcNyxxX_8P",
    "outputId": "46e47947-c191-4c72-e72d-2a366d3ff892"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li role=\"example_1\"> By tag: we could search for every li </li>,\n",
       " <li role=\"example_2\"> By id: we could search for the p tag with id=\"searching_description\" </li>,\n",
       " <li class=\"important\" role=\"example_3\"> By class: we could search for every tag with a given class </li>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def important_role(role_attribute):\n",
    "    return role_attribute != None and 'example_' in role_attribute\n",
    "\n",
    "# Find the first <ol> element\n",
    "ol_element = soup.find('ol')\n",
    "ol_element.find_all('li', role=important_role) # Finding all the list elements with a role attribute that contains 'example-'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYB_HDsyYDwP"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.2.5 **Bonus**: Searching using CSS selectors.\n",
    "\n",
    "We can also use the `.select()` method to search for elements using CSS notation. Here's how we would define styles in a CSS file to apply HTML tags, classes, and ids:\n",
    "- p {} -> applies to all HTML 'p' tags\n",
    "- #chart {} -> applies to all HTML elements with the attribute class=\"chart\"\n",
    "- .chart1 {} -> applies to all HTML elements with the attribute id=\"chart1\"\n",
    "\n",
    "`figure`, `#chart1`, `.chart1` are each CSS selectors. We can pass this to the `.select()` method to extract matching elements.\n",
    "\n",
    "- **Note**: we can achieve the same results with the .find .find_all etc methods we showed above, but using CSS selectors can be nice as it keeps the same system we're used to when using CSS on our own website.\n",
    "\n",
    "- **Tip**: There are more useful features of the `.select()` method that allow for complex searching (such as by attribute or for the nth type). [More info here](https://www.tutorialspoint.com/beautiful_soup/beautiful_soup_find_element_using_css_selectors.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eatK-e1fX3-C",
    "outputId": "5d72cefa-6218-4fdf-d63c-9e381a126498"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p> BeautifulSoup is a Python library for parsing HTML documents. We can use it to extract data from HTML we fetch\n",
       "         from the web.\n",
       "         Here, we're just using it to parse some simple sample HTML.\n",
       "     </p>,\n",
       " <p id=\"searching_description\" style=\"color: red\"> BeautifulSoup allows us to search the HTML tree in lots of different ways: by tag, by\n",
       "         id, by CSS class, and so on. </p>,\n",
       " <p>Div tags are used to group block-elements and structure the web page.</p>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0kZBVnbYFX6",
    "outputId": "af44218a-b570-4f44-8178-de2e243babc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"searching_description\" style=\"color: red\"> BeautifulSoup allows us to search the HTML tree in lots of different ways: by tag, by\n",
       "         id, by CSS class, and so on. </p>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for elements with id=\"searching_description\"\n",
    "soup.select('#searching_description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "owBj1BmMYKu_",
    "outputId": "682b8086-125c-4543-a548-43129aa58f05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"searching_description\" style=\"color: red\"> BeautifulSoup allows us to search the HTML tree in lots of different ways: by tag, by\n",
       "         id, by CSS class, and so on. </p>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for p elements with a style attribute (it doesn't matter what the value of the style attribute is)\n",
    "soup.select('p[style]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZK_f1xkYPqH"
   },
   "source": [
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ao1zHFqGYTDl"
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# Part 2. Live HTML\n",
    "\n",
    "## Getting HTML from the web with `Requests`\n",
    "\n",
    "<div style=\"display: flex; align-items: flex-start;\">\n",
    "    <div style=\"flex: 0 2 auto;\">\n",
    "        <img src=\"https://raw.githubusercontent.com/FM-ds/ScrapingWorkshop/main/notebook_images/sample_html_safari.png\" width=\"400px\">\n",
    "    </div>\n",
    "    <div style=\"flex: 1 1 auto; margin-top: 10px; margin-right: 150px\">\n",
    "        <p>We just extracted information from HTML which was defined locally in a string <code>sample_html</code>. Usually, we care about HTML found on the internet. As a simple example, the page defined in <code>sample_html</code> is available at <a href=\"http://www.fmcevoy.io/ScrapingWorkshop/sample_html\">http://www.fmcevoy.io/ScrapingWorkshop/sample_html</a></p>\n",
    "        <p>To download HTML (and any other resources) from the internet, we can use the <code>requests</code> module.</p>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "gBXOvmxMYXI2"
   },
   "outputs": [],
   "source": [
    "import requests                # for making HTTP requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtuuP2WJYZsc"
   },
   "source": [
    "We'll use the `.get()` method with our target URL to make this request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "no4SL5GuYQ0l",
    "outputId": "50174443-bbd0-4269-920f-d457cc47c299"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<body>\n",
      "    <h1> BeautifulSoup </h1>\n",
      "    <p> BeautifulSoup is a Python library for parsing HTML documents. We can use it to extract data from HTML we fetch\n",
      "        from the web.\n",
      "        Here, we're just using it to parse some simple sample HTML. </p>\n",
      "\n",
      "    <h2 class=\"important\"> Searching the tree </h2>\n",
      "    <p id=\"searching_description\" style=\"color: red\"> BeautifulSoup allows us to search th ...\n"
     ]
    }
   ],
   "source": [
    "response = requests.get('http://www.fmcevoy.io/ScrapingWorkshop/sample_html') # Making a request for the sample HTML hosted on the web\n",
    "\n",
    "# Let's check the content of our get request (showing only the first 400 characters)\n",
    "print(response.text[:400], '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "at26N2Y9Yh72"
   },
   "source": [
    "We've successfully managed to use Python code to fetch HTML code from the web!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsT0b07xYkEE"
   },
   "source": [
    "<br>\n",
    "\n",
    "**Parsing** - We need to convert the HTML code from normal text (i.e. string) into some format that we can search. Just as we did before, we'll use BeautifulSoup to parse the response into a special `soup` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5SVk7bw-Ymbz",
    "outputId": "08e9131b-6649-4672-d272-8f8e0dffcd27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li role=\"example_1\"> By tag: we could search for every li </li>,\n",
       " <li role=\"example_2\"> By id: we could search for the p tag with id=\"searching_description\" </li>,\n",
       " <li class=\"important\" role=\"example_3\"> By class: we could search for every tag with a given class </li>,\n",
       " <li> and so on... </li>,\n",
       " <li><a href=\"https://example.com/page1\">Page 1</a></li>,\n",
       " <li><a href=\"https://example.com/page2\">Page 2</a></li>,\n",
       " <li><a href=\"https://example.com/page3\">Page 3</a></li>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser') # Instead of using the sample HTML, we're using the HTML from the web that we fetched in the previous step\n",
    "soup.find_all('li') # Finding all the list elements in the HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qW96D7nYn8n"
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "### <font color='Green'><strong>Exercises: </strong></font>\n",
    "\n",
    "**EX 1** Retrieve the text of the paragraph (`<p>`) with the id \"exercise1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1tfHyj-AYflW"
   },
   "outputs": [],
   "source": [
    "### 1. Add Solution Here ###\n",
    "exercise1 = # TODO: Add your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGlcYo93Yq5-"
   },
   "source": [
    "<br>\n",
    "\n",
    "**EX 2** Count the number of `<div>` elements on the page that have the class \"exercise\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MygqCjDaYwZK"
   },
   "outputs": [],
   "source": [
    "### 2. Add Solution Here ###\n",
    "exercise_divs = #TODO: Add your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEeOu28iYxd0"
   },
   "source": [
    "<br>\n",
    "\n",
    "**EX 3** Extract and print all the URLs from the anchor (`<a>`) tags within the list in div with the id \"exercise3\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VhuenewVY31i"
   },
   "outputs": [],
   "source": [
    "### 3. Add Solution Here ###\n",
    "\n",
    "anchor_tags = #TODO: Add your solution here\n",
    "for tag in anchor_tags:\n",
    "    # TODO: print the href attribute of each anchor tag\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
